{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nIf you are running locally then \\n1. reboot your local machine\\n2. create an environment called 'colab' using anaconda prompt\\nif you have a gpu\\nconda create -n colab python tensorflow-gpu \\nif not \\nconda create -n colab python tensorflow\\n3. to install jupyter notebook\\nconda install jupyter notebook\\n4. to go to the 'colab' environment\\nactivate colab\\n5. change file path to locate this notebook and then type 'jupyter notebook'\\n\\nIf you use colab\\n1. save the data file in your google drive\\n2. goto colab and start running the code\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "If you are running locally then \n",
    "1. reboot your local machine\n",
    "2. create an environment called 'colab' using anaconda prompt\n",
    "if you have a gpu\n",
    "conda create -n colab python tensorflow-gpu \n",
    "if not \n",
    "conda create -n colab python tensorflow\n",
    "3. to install jupyter notebook\n",
    "conda install jupyter notebook\n",
    "4. to go to the 'colab' environment\n",
    "activate colab\n",
    "5. change file path to locate this notebook and then type 'jupyter notebook'\n",
    "\n",
    "If you use colab\n",
    "1. save the data file in your google drive\n",
    "2. goto colab and start running the code\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install prominent libraries with specific versions\n",
    "\n",
    "#!pip install tensorflow==1.15.0\n",
    "#!pip install keras==2.2.4-tf\n",
    "#!pip install pandas==0.25.1\n",
    "#!pip install sklearn==0.21.3\n",
    "#!pip install matplotlib==3.2.1\n",
    "#!pip install hyperas\n",
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "colab_type": "code",
    "id": "sJnnN6xG_yaM",
    "outputId": "b6420ce8-7f05-440c-e2ce-479b5bc1cafc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\kenneth\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function                                                                                                                                                                                                                                                                                                                              # from tensorflow.contrib.rnn import *import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, CuDNNLSTM,GRU, Input, Activation, Flatten, BatchNormalization, Reshape,Concatenate\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, History\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import*\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import SGD, RMSprop, Adam, Adadelta\n",
    "from keras.utils import np_utils, to_categorical\n",
    "import pandas as pd\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from collections import Counter\n",
    "import operator\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import hyperas\n",
    "import hyperopt\n",
    "from hyperas.distributions import choice, uniform\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe, rand\n",
    "from keras.layers import Conv1D, MaxPooling1D, ZeroPadding1D\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow.__version__ =  1.10.0\n",
      "keras.__version__ =  2.1.6-tf\n",
      "sklearn.__version__ =  0.21.3\n",
      "numpy.__version__ =  1.17.0\n",
      "pandas.__version__ =  1.0.1\n",
      "matplotlib.__version__ =  3.1.3\n"
     ]
    }
   ],
   "source": [
    "#Get library versions\n",
    "print(\"tensorflow.__version__ = \", tf.__version__)\n",
    "print(\"keras.__version__ = \", keras.__version__)\n",
    "import sklearn \n",
    "print(\"sklearn.__version__ = \", sklearn.__version__)\n",
    "print(\"numpy.__version__ = \", np.__version__)\n",
    "print(\"pandas.__version__ = \", pd.__version__)\n",
    "import matplotlib\n",
    "print(\"matplotlib.__version__ = \", matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed to generate reproduceable results\n",
    "from numpy.random import seed\n",
    "seed(56)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(56)\n",
    "random.seed(56)\n",
    "os.environ['PYTHONHASHSEED']=str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create these folders if they do not exist\n",
    "def build_path(dirName):\n",
    "    try:\n",
    "        os.makedirs(dirName)    \n",
    "        print(\"Directory \" , dirName ,  \" Created \")\n",
    "    except:\n",
    "        print(\"Directory \" , dirName ,  \" already exists\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13966607730014851906\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7134468506\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4202884569358172624\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# to check if GPU is getting used locally.....you need to see CPU as well as GPU in the output\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oOs6JYN__51O"
   },
   "outputs": [],
   "source": [
    "def data():\n",
    "  i = 7 # the label target - number of days to predict from the input date\n",
    "  p = 7 #Number of days for target calculated in the data set\n",
    "  batch_size=32\n",
    "  CLASSES = 2\n",
    "  time_steps = 7\n",
    "  ticker='^GSPC'\n",
    "    \n",
    "  # read data\n",
    "  df=pd.read_csv('../^GSPC_7_days_0_return_dtw.csv', index_col = 0, parse_dates = True)\n",
    "    \n",
    "  #add additional rolling mean data  \n",
    "  rm_window =30\n",
    "  rolling_mean = []\n",
    "  for a in range(2,rm_window+1):\n",
    "    df[ticker+'rm_'+str(a)] = df[ticker].rolling(window=rm_window,center=False).mean()\n",
    "    rolling_mean.append(ticker+'rm_'+str(a))\n",
    "    \n",
    "  # create label\n",
    "  targets=pd.DataFrame([])\n",
    "  for j in range (1, p+1):\n",
    "    targets=targets.append(df[ticker+'_{}d_target'.format(j)])\n",
    "    targets=targets.append(df[ticker+'_{}d'.format(j)])\n",
    "  targets=targets.T\n",
    "  df=df.drop(targets.columns, axis=1)\n",
    "  df=df[rm_window:-i]\n",
    "  targets=targets[rm_window:-i]\n",
    "  y=targets['^GSPC_{}d_target'.format(i)]\n",
    "\n",
    "  #check for NaN and remove\n",
    "  df.isna().mean().sum()\n",
    "  y.isna().mean().sum()\n",
    "  remove_list=[]\n",
    "  for i in df.isnull().any().iteritems():\n",
    "    if i[1] == True:\n",
    "      remove_list.append(i[0])\n",
    "  df=df.drop(remove_list, axis=1)\n",
    "  df.isnull().any().mean()\n",
    " \n",
    "  # add percent change\n",
    "  df=df.pct_change()\n",
    "  df=df.replace([np.inf, -np.inf],np.nan) \n",
    "  df.fillna(0, inplace=True)\n",
    "  df.isnull().any().mean()\n",
    "    \n",
    "  # apply preprocessing \n",
    "  x_scaler=RobustScaler()\n",
    "  x = x_scaler.fit_transform(df)\n",
    "  # x_pred = x_scaler.fit_transform(x_pred)\n",
    "  del df\n",
    "  y=y.values\n",
    "    \n",
    "  # apply time steps\n",
    "  def create_dataset(X, y, time_steps=1):\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps):\n",
    "      v = X[i:(i + time_steps)]\n",
    "      Xs.append(v)\n",
    "      ys.append(y[i + time_steps])\n",
    "    return np.array(Xs), np.array(ys)\n",
    "  x, y = create_dataset(x, y, time_steps)\n",
    "\n",
    "  # create train and test dataset\n",
    "  x_train, x_test, y_train, y_test=train_test_split(x,y, train_size=0.7, random_state=54)\n",
    "  x_train = x_train.astype('float32')\n",
    "  x_test = x_test.astype('float32')\n",
    "  #y_train = y_train.astype('float32')\n",
    "  #y_test = y_test.astype('float32')\n",
    "  y_train = np_utils.to_categorical(y_train, CLASSES, dtype='float32')\n",
    "  y_test = np_utils.to_categorical(y_test, CLASSES, dtype='float32')\n",
    "    \n",
    "  # adjustment for batch_size\n",
    "  train_start = x_train.shape[0]%batch_size\n",
    "  test_start = x_test.shape[0]%batch_size\n",
    "  x_train = x_train[train_start:]\n",
    "  y_train = y_train[train_start:]\n",
    "  x_test = x_test[test_start:]\n",
    "  y_test = y_test[test_start:]\n",
    "\n",
    "  return x_train, x_test, y_train, y_test, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rc8hDOIbADgQ"
   },
   "outputs": [],
   "source": [
    "def create_self_attention_lstm_model(x_train, x_test, y_train, y_test, batch_size):\n",
    "    \n",
    "    class Attention(Layer):\n",
    "        def __init__(self, step_dim,\n",
    "                     W_regularizer=None, b_regularizer=None,\n",
    "                     W_constraint=None, b_constraint=None,\n",
    "                     bias=True, **kwargs):\n",
    "            self.supports_masking = True\n",
    "            self.init = initializers.get('glorot_uniform')\n",
    "            self.W_regularizer = regularizers.get(W_regularizer)\n",
    "            self.b_regularizer = regularizers.get(b_regularizer)\n",
    "            self.W_constraint = constraints.get(W_constraint)\n",
    "            self.b_constraint = constraints.get(b_constraint)\n",
    "            self.bias = bias\n",
    "            self.step_dim = step_dim\n",
    "            self.features_dim = 0\n",
    "            super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "        def build(self, input_shape):\n",
    "            assert len(input_shape) == 3\n",
    "            self.W = self.add_weight(shape=(input_shape[-1],),\n",
    "                                     initializer=self.init,\n",
    "                                     name='{}_W'.format(self.name),\n",
    "                                     regularizer=self.W_regularizer,\n",
    "                                     constraint=self.W_constraint)\n",
    "            self.features_dim = input_shape[-1]\n",
    "            if self.bias:\n",
    "                self.b = self.add_weight(shape=(input_shape[1],),\n",
    "                                         initializer='zero',\n",
    "                                         name='{}_b'.format(self.name),\n",
    "                                         regularizer=self.b_regularizer,\n",
    "                                         constraint=self.b_constraint)\n",
    "            else:\n",
    "                self.b = None\n",
    "            self.built = True\n",
    "\n",
    "        def compute_mask(self, input, input_mask=None):\n",
    "            return None\n",
    "\n",
    "        def call(self, x, mask=None):\n",
    "            features_dim = self.features_dim\n",
    "            step_dim = self.step_dim\n",
    "            eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))),\n",
    "                            (-1, step_dim))\n",
    "            if self.bias:\n",
    "                eij += self.b\n",
    "            eij = K.tanh(eij)\n",
    "            a = K.exp(eij)\n",
    "            if mask is not None:\n",
    "                a *= K.cast(mask, K.floatx())\n",
    "            a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "            a = K.expand_dims(a)\n",
    "            weighted_input = x * a\n",
    "            return K.sum(weighted_input, axis=1)\n",
    "\n",
    "        def compute_output_shape(self, input_shape):\n",
    "            return input_shape[0],  self.features_dim\n",
    "   \n",
    "   \n",
    "    \n",
    "    x0 = Input(shape=(x_train.shape[1], x_train.shape[2]), name='x0')\n",
    "    x1 = (CuDNNLSTM(units = {{choice([24,32,64,128])}}, \n",
    "               kernel_regularizer=regularizers.l2({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}), \n",
    "               bias_regularizer=regularizers.l1({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}),\n",
    "              return_sequences=True))(x0)\n",
    "\n",
    "    x3 = BatchNormalization()(x2)\n",
    "    x4 = Dropout({{uniform(0, 1)}})(x3)\n",
    "    # x3 = (LSTM(24, kernel_regularizer=regularizers.l2(0.03),bias_regularizer=regularizers.l1(0.03),\n",
    "    #           return_sequences=True))(x2)\n",
    "    # x3 = LeakyReLU(alpha=0.05)(x3)\n",
    "    # x3 = BatchNormalization()(x3)\n",
    "    # x4 = Dropout(0.6)(x3)\n",
    "    x5 = Attention(7)(x4)\n",
    "    x6 = Dense(units = {{choice([42, 64, 128])}}, \n",
    "               kernel_regularizer=regularizers.l2({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}), \n",
    "               bias_regularizer=regularizers.l1({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}),\n",
    "               activation='relu')(x5)\n",
    "    x7 = Dropout({{uniform(0, 1)}})(x6)\n",
    "    x8 = Dense(units = {{choice([16, 32, 64])}}, \n",
    "               kernel_regularizer=regularizers.l2({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}), \n",
    "               bias_regularizer=regularizers.l1({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}),\n",
    "               activation='relu')(x7)\n",
    "    x9 = BatchNormalization()(x8)\n",
    "    x10 = Dropout({{uniform(0, 1)}})(x9)\n",
    "    x11 = Dense(units = {{choice([8, 16, 32])}},\n",
    "                kernel_regularizer=regularizers.l2({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}), \n",
    "               bias_regularizer=regularizers.l1({{choice([0.01,0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1])}}),\n",
    "                activation='relu')(x10)\n",
    "    x12 = Dropout({{uniform(0, 1)}})(x11)\n",
    "    # x13 = BatchNormalization()(x12)\n",
    "    outp = Dense(2, activation='softmax')(x12)\n",
    "\n",
    "    model = Model(inputs=[x0], outputs=outp)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer = Adam(lr={{choice([1.0, 0.1,0.01,0.001])}}))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    result = model.fit(x_train,y_train,batch_size=batch_size,epochs=10,validation_data=(x_test, y_test), verbose=0)\n",
    "    \n",
    "    validation_acc = np.amax(result.history['val_acc']) \n",
    "\n",
    "    print('Best validation acc of epoch:', result.history['val_acc'])\n",
    "    print('Train acc of epoch:', result.history['acc'])\n",
    "    return {'loss': -validation_acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HcxtusN4AK8y",
    "outputId": "43d151c2-cf3b-4ab8-e95f-7c48cef1da49",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8832, 7, 2782) (8832, 2) (3776, 7, 2782) (3776, 2)\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_1 (LSTM)                (None, 7, 64)             728832                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 7, 64)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_1 (Batch (None, 7, 64)             256                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_1 (Dropout)          (None, 7, 64)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_1 (Attention)      (None, 64)                71                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_1 (Dense)              (None, 128)               8320                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_2 (Dropout)          (None, 128)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_2 (Dense)              (None, 32)                4128                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_2 (Batch (None, 32)                128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_3 (Dropout)          (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_3 (Dense)              (None, 32)                1056                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_4 (Dropout)          (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_4 (Dense)              (None, 2)                 66                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 742,857                                                                                                  \n",
      "Trainable params: 742,665                                                                                              \n",
      "Non-trainable params: 192                                                                                              \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5561440677966102, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5820974576271186]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5302309782608695, 0.5720108695652174, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5749547101449275, 0.5752943840579711, 0.581634963768116, 0.5913722826086957]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_2 (LSTM)                (None, 7, 32)             360320                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_3 (Batch (None, 7, 32)             128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_5 (Dropout)          (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_2 (Attention)      (None, 32)                39                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_5 (Dense)              (None, 128)               4224                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_6 (Dropout)          (None, 128)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_6 (Dense)              (None, 32)                4128                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_4 (Batch (None, 32)                128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_7 (Dropout)          (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_7 (Dense)              (None, 32)                1056                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_8 (Dropout)          (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_8 (Dense)              (None, 2)                 66                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 370,089                                                                                                  \n",
      "Trainable params: 369,961                                                                                              \n",
      "Non-trainable params: 128                                                                                              \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5566737288135594, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5259284420289855, 0.5651041666666666, 0.5747282608695652, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_3 (LSTM)                (None, 7, 128)            1490432                                                         \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 7, 128)            0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_5 (Batch (None, 7, 128)            512                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_9 (Dropout)          (None, 7, 128)            0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_3 (Attention)      (None, 128)               135                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dense_9 (Dense)              (None, 42)                5418                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_10 (Dropout)         (None, 42)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_10 (Dense)             (None, 16)                688                                                             \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_6 (Batch (None, 16)                64                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_11 (Dropout)         (None, 16)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_11 (Dense)             (None, 32)                544                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_12 (Dropout)         (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_12 (Dense)             (None, 2)                 66                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 1,497,859                                                                                                \n",
      "Trainable params: 1,497,571                                                                                            \n",
      "Non-trainable params: 288                                                                                              \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5558792372881356, 0.4441207627118644, 0.444385593220339, 0.4441207627118644, 0.4441207627118644, 0.4510063559322034, 0.4441207627118644, 0.5558792372881356, 0.4472987288135593, 0.5402542372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5318161231884058, 0.5461956521739131, 0.5225317028985508, 0.5264945652173914, 0.4557291666666667, 0.458786231884058, 0.44972826086956524, 0.5020380434782609, 0.5548007246376812, 0.5075860507246377]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_4 (LSTM)                (None, 7, 24)             269472                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_7 (Batch (None, 7, 24)             96                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_13 (Dropout)         (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_4 (Attention)      (None, 24)                31                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________                                                      \n",
      "dense_13 (Dense)             (None, 42)                1050                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_14 (Dropout)         (None, 42)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_14 (Dense)             (None, 32)                1376                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_8 (Batch (None, 32)                128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_15 (Dropout)         (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_15 (Dense)             (None, 16)                528                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_16 (Dropout)         (None, 16)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_16 (Dense)             (None, 2)                 34                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 272,715                                                                                                  \n",
      "Trainable params: 272,603                                                                                              \n",
      "Non-trainable params: 112                                                                                              \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.4441207627118644, 0.5579978813559322, 0.5558792372881356, 0.4441207627118644, 0.4441207627118644, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.566802536231884, 0.5739356884057971, 0.5414402173913043, 0.533401268115942, 0.5529891304347826, 0.505661231884058, 0.5619338768115942, 0.5159646739130435, 0.42844202898550726, 0.4600317028985507]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_5 (LSTM)                (None, 7, 24)             269472                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_9 (Batch (None, 7, 24)             96                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_17 (Dropout)         (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_5 (Attention)      (None, 24)                31                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_17 (Dense)             (None, 64)                1600                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_18 (Dropout)         (None, 64)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_18 (Dense)             (None, 32)                2080                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_10 (Batc (None, 32)                128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_19 (Dropout)         (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_19 (Dense)             (None, 8)                 264                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_20 (Dropout)         (None, 8)                 0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_20 (Dense)             (None, 2)                 18                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 273,689                                                                                                  \n",
      "Trainable params: 273,577                                                                                              \n",
      "Non-trainable params: 112                                                                                              \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5609148550724637, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_6 (LSTM)                (None, 7, 32)             360320                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_11 (Batc (None, 7, 32)             128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_21 (Dropout)         (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_6 (Attention)      (None, 32)                39                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_21 (Dense)             (None, 42)                1386                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_22 (Dropout)         (None, 42)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_22 (Dense)             (None, 32)                1376                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_12 (Batc (None, 32)                128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_23 (Dropout)         (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_23 (Dense)             (None, 32)                1056                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_24 (Dropout)         (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_24 (Dense)             (None, 2)                 66                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 364,499                                                                                                  \n",
      "Trainable params: 364,371                                                                                              \n",
      "Non-trainable params: 128                                                                                              \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.4441207627118644, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5562726449275363, 0.5721240942028986, 0.5414402173913043, 0.5495923913043478, 0.5466485507246377, 0.5498188405797102, 0.5471014492753623, 0.5096240942028986, 0.5224184782608695, 0.5435914855072463]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_7 (LSTM)                (None, 7, 32)             360320                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_13 (Batc (None, 7, 32)             128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_25 (Dropout)         (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_7 (Attention)      (None, 32)                39                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_25 (Dense)             (None, 42)                1386                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_26 (Dropout)         (None, 42)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_26 (Dense)             (None, 16)                688                                                             \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_14 (Batc (None, 16)                64                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_27 (Dropout)         (None, 16)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_27 (Dense)             (None, 16)                272                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_28 (Dropout)         (None, 16)                0                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________                                                      \n",
      "dense_28 (Dense)             (None, 2)                 34                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 362,931                                                                                                  \n",
      "Trainable params: 362,835                                                                                              \n",
      "Non-trainable params: 96                                                                                               \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.559322033898305, 0.5561440677966102, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5105298913043478, 0.5381567028985508, 0.5703125, 0.571671195652174, 0.5750679347826086, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_8 (LSTM)                (None, 7, 32)             360320                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_15 (Batc (None, 7, 32)             128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_29 (Dropout)         (None, 7, 32)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_8 (Attention)      (None, 32)                39                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_29 (Dense)             (None, 128)               4224                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_30 (Dropout)         (None, 128)               0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_30 (Dense)             (None, 16)                2064                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_16 (Batc (None, 16)                64                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_31 (Dropout)         (None, 16)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_31 (Dense)             (None, 8)                 136                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_32 (Dropout)         (None, 8)                 0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_32 (Dense)             (None, 2)                 18                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 366,993                                                                                                  \n",
      "Trainable params: 366,897                                                                                              \n",
      "Non-trainable params: 96                                                                                               \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.4441207627118644, 0.4441207627118644, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.48709239130434784, 0.47475090579710144, 0.5079257246376812, 0.5757472826086957, 0.5722373188405797, 0.5613677536231884, 0.5466485507246377, 0.5708786231884058, 0.5725769927536232, 0.5721240942028986]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_9 (LSTM)                (None, 7, 24)             269472                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_17 (Batc (None, 7, 24)             96                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_33 (Dropout)         (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_9 (Attention)      (None, 24)                31                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_33 (Dense)             (None, 64)                1600                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_34 (Dropout)         (None, 64)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_34 (Dense)             (None, 16)                1040                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_18 (Batc (None, 16)                64                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_35 (Dropout)         (None, 16)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_35 (Dense)             (None, 8)                 136                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_36 (Dropout)         (None, 8)                 0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_36 (Dense)             (None, 2)                 18                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 272,457                                                                                                  \n",
      "Trainable params: 272,377                                                                                              \n",
      "Non-trainable params: 80                                                                                               \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5558792372881356, 0.4441207627118644, 0.5558792372881356, 0.4441207627118644, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5350996376811594, 0.5275135869565217, 0.5296648550724637, 0.5383831521739131, 0.5424592391304348, 0.541213768115942, 0.5332880434782609, 0.5466485507246377, 0.5465353260869565, 0.5424592391304348]\n",
      "_________________________________________________________________                                                      \n",
      "Layer (type)                 Output Shape              Param #                                                         \n",
      "=================================================================                                                      \n",
      "x0 (InputLayer)              (None, 7, 2782)           0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "lstm_10 (LSTM)               (None, 7, 24)             269472                                                          \n",
      "_________________________________________________________________                                                      \n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_19 (Batc (None, 7, 24)             96                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dropout_37 (Dropout)         (None, 7, 24)             0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "attention_10 (Attention)     (None, 24)                31                                                              \n",
      "_________________________________________________________________                                                      \n",
      "dense_37 (Dense)             (None, 42)                1050                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_38 (Dropout)         (None, 42)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_38 (Dense)             (None, 32)                1376                                                            \n",
      "_________________________________________________________________                                                      \n",
      "batch_normalization_20 (Batc (None, 32)                128                                                             \n",
      "_________________________________________________________________                                                      \n",
      "dropout_39 (Dropout)         (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_39 (Dense)             (None, 32)                1056                                                            \n",
      "_________________________________________________________________                                                      \n",
      "dropout_40 (Dropout)         (None, 32)                0                                                               \n",
      "_________________________________________________________________                                                      \n",
      "dense_40 (Dense)             (None, 2)                 66                                                              \n",
      "=================================================================                                                      \n",
      "Total params: 273,275                                                                                                  \n",
      "Trainable params: 273,163                                                                                              \n",
      "Non-trainable params: 112                                                                                              \n",
      "_________________________________________________________________                                                      \n",
      "Best validation acc of epoch:                                                                                          \n",
      "[0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356, 0.5558792372881356]\n",
      "Train acc of epoch:                                                                                                    \n",
      "[0.5687273550724637, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5748414855072463, 0.5734827898550725, 0.5748414855072463]\n",
      "100%|██████████████████████████████████████████████████| 10/10 [15:58<00:00, 96.76s/it, best loss: -0.5820974576271186]\n",
      "Evaluation of best performing model:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'model_1', 'layers': [{'name': 'x0', 'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 7, 2782), 'dtype': 'float32', 'sparse': False, 'name': 'x0'}, 'inbound_nodes': []}, {'name': 'lstm_1', 'class_name': 'LSTM', 'config': {'name': 'lstm_1', 'trainable': True, 'return_sequences': True, 'return_state': False, 'go_backwards': False, 'stateful': False, 'unroll': False, 'units': 64, 'activation': 'tanh', 'recurrent_activation': 'hard_sigmoid', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'recurrent_initializer': {'class_name': 'Orthogonal', 'config': {'gain': 1.0, 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'unit_forget_bias': True, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 0.019999999552965164}}, 'recurrent_regularizer': None, 'bias_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.03999999910593033, 'l2': 0.0}}, 'activity_regularizer': None, 'kernel_constraint': None, 'recurrent_constraint': None, 'bias_constraint': None, 'dropout': 0.0, 'recurrent_dropout': 0.0, 'implementation': 1}, 'inbound_nodes': [[['x0', 0, 0, {}]]]}, {'name': 'leaky_re_lu_1', 'class_name': 'LeakyReLU', 'config': {'name': 'leaky_re_lu_1', 'trainable': True, 'alpha': 0.009999999776482582}, 'inbound_nodes': [[['lstm_1', 0, 0, {}]]]}, {'name': 'batch_normalization_1', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_1', 'trainable': True, 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'inbound_nodes': [[['leaky_re_lu_1', 0, 0, {}]]]}, {'name': 'dropout_1', 'class_name': 'Dropout', 'config': {'name': 'dropout_1', 'trainable': True, 'rate': 0.17244883597095362, 'noise_shape': None, 'seed': None}, 'inbound_nodes': [[['batch_normalization_1', 0, 0, {}]]]}, {'name': 'attention_1', 'class_name': 'Attention', 'config': {'name': 'attention_1', 'trainable': True}, 'inbound_nodes': [[['dropout_1', 0, 0, {}]]]}, {'name': 'dense_1', 'class_name': 'Dense', 'config': {'name': 'dense_1', 'trainable': True, 'units': 128, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 0.09000000357627869}}, 'bias_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.10000000149011612, 'l2': 0.0}}, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'inbound_nodes': [[['attention_1', 0, 0, {}]]]}, {'name': 'dropout_2', 'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'rate': 0.17340017402450802, 'noise_shape': None, 'seed': None}, 'inbound_nodes': [[['dense_1', 0, 0, {}]]]}, {'name': 'dense_2', 'class_name': 'Dense', 'config': {'name': 'dense_2', 'trainable': True, 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 0.10000000149011612}}, 'bias_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.05999999865889549, 'l2': 0.0}}, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'inbound_nodes': [[['dropout_2', 0, 0, {}]]]}, {'name': 'batch_normalization_2', 'class_name': 'BatchNormalization', 'config': {'name': 'batch_normalization_2', 'trainable': True, 'axis': -1, 'momentum': 0.99, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': {'class_name': 'Zeros', 'config': {}}, 'gamma_initializer': {'class_name': 'Ones', 'config': {}}, 'moving_mean_initializer': {'class_name': 'Zeros', 'config': {}}, 'moving_variance_initializer': {'class_name': 'Ones', 'config': {}}, 'beta_regularizer': None, 'gamma_regularizer': None, 'beta_constraint': None, 'gamma_constraint': None}, 'inbound_nodes': [[['dense_2', 0, 0, {}]]]}, {'name': 'dropout_3', 'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'rate': 0.04085564002777442, 'noise_shape': None, 'seed': None}, 'inbound_nodes': [[['batch_normalization_2', 0, 0, {}]]]}, {'name': 'dense_3', 'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'units': 32, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.0, 'l2': 0.019999999552965164}}, 'bias_regularizer': {'class_name': 'L1L2', 'config': {'l1': 0.029999999329447746, 'l2': 0.0}}, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'inbound_nodes': [[['dropout_3', 0, 0, {}]]]}, {'name': 'dropout_4', 'class_name': 'Dropout', 'config': {'name': 'dropout_4', 'trainable': True, 'rate': 0.4781260343676643, 'noise_shape': None, 'seed': None}, 'inbound_nodes': [[['dense_3', 0, 0, {}]]]}, {'name': 'dense_4', 'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'units': 2, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}, 'inbound_nodes': [[['dropout_4', 0, 0, {}]]]}], 'input_layers': [['x0', 0, 0]], 'output_layers': [['dense_4', 0, 0]]}\n",
      "3776/3776 [==============================] - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 2s 407us/step\n",
      "test_score:  0.9910265293161747  test_accuracy:  0.5820974576271186\n",
      "Best performing model chosen hyper-parameters:\n",
      "{'Dropout': 0.17244883597095362, 'Dropout_1': 0.17340017402450802, 'Dropout_2': 0.04085564002777442, 'Dropout_3': 0.4781260343676643, 'l2': 1, 'l2_1': 3, 'l2_2': 0, 'l2_3': 8, 'l2_4': 9, 'l2_5': 9, 'l2_6': 5, 'l2_7': 1, 'l2_8': 2, 'lr': 3, 'units': 2, 'units_1': 2, 'units_2': 1, 'units_3': 2}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    x_train, x_test, y_train, y_test, batch_size  = data()\n",
    "    print(x_train.shape,y_train.shape,x_test.shape,y_test.shape)\n",
    "    \n",
    "    best_run, best_model = optim.minimize(model=create_self_attention_lstm_model, data=data ,algo=tpe.suggest, \n",
    "                                          max_evals=10,trials=Trials(), notebook_name='4.1 Self_Attention_CuDNNLSTM',rseed=56, verbose=False)\n",
    "    print(\"Evaluation of best performing model:\")\n",
    "    best_model.save(\"SELF_ATTENTION_CUDNNLSTM_bestmodel.h5\")\n",
    "    print(best_model.get_config())\n",
    "    test_score, test_accuracy = best_model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "    print('test_score: ', test_score, ' test_accuracy: ', test_accuracy)\n",
    "    print(\"Best performing model chosen hyper-parameters:\")\n",
    "    print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "GSPC_7days_CNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:gpu]",
   "language": "python",
   "name": "conda-env-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
